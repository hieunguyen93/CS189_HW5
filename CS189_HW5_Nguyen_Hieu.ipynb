{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Homework 5\n",
    "## CS 189, Spring 2021\n",
    "## Author: Hieu Nguyen \n",
    "## SID: 26369732\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from numpy import genfromtxt\n",
    "import sklearn.tree\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "eps = 1e-5  # a small number\n",
    "\n",
    "def preprocess(data, fill_mode=True, min_freq=4, onehot_cols=[]):\n",
    "    # fill_mode = False\n",
    "\n",
    "    # Temporarily assign -1 to missing data\n",
    "    data[data == b''] = '-1'\n",
    "\n",
    "    # Hash the columns (used for handling strings)\n",
    "    onehot_encoding = []\n",
    "    onehot_features = []\n",
    "    for col in onehot_cols:\n",
    "        counter = Counter(data[:, col])\n",
    "        for term in counter.most_common():\n",
    "            #print(term)\n",
    "            if term[0] == b'-1':\n",
    "                continue\n",
    "            if term[-1] <= min_freq:\n",
    "                break\n",
    "            onehot_features.append(term[0])\n",
    "            onehot_encoding.append((data[:, col] == term[0]).astype(np.float))\n",
    "        data[:, col] = '0'\n",
    "    onehot_encoding = np.array(onehot_encoding).T\n",
    "    data = np.hstack([np.array(data, dtype=np.float), np.array(onehot_encoding)])\n",
    "\n",
    "    # Replace missing data with the mode value. We use the mode instead of\n",
    "    # the mean or median because this makes more sense for categorical\n",
    "    # features such as gender or cabin type, which are not ordered.\n",
    "\n",
    "    if fill_mode:\n",
    "        for i in range(data.shape[-1]):\n",
    "            \n",
    "            mode = stats.mode(data[data[:, i] != -1][:, i]).mode[0]\n",
    "            np.put(data[:, i], np.where(data[:, i] == -1), mode)\n",
    "\n",
    "            # print(\"feature {} has mode {}\".format(i, mode))\n",
    "            # mode = stats.mode(data[((data[:, i] < -1 - eps) +\n",
    "            #                         (data[:, i] > -1 + eps))][:, i]).mode[0]\n",
    "            # data[(data[:, i] > -1 - eps) * (data[:, i] < -1 + eps)][:, i] = mode\n",
    "\n",
    "    return data, onehot_features\n",
    "\n",
    "\n",
    "def generateKFold(X, y, k=5):\n",
    "    full = np.concatenate((X,y), axis=1)\n",
    "    np.random.shuffle(full)\n",
    "    return np.array_split(full, 5, axis=0)\n",
    "\n",
    "def split_xy(data):\n",
    "    return data[:, :-1], data[:, -1:]\n",
    "\n",
    "def pickKFold(kfold, index):\n",
    "    val = kfold[index]\n",
    "    \n",
    "    toTrain = kfold[:index] + kfold[index+1:]\n",
    "    train = np.concatenate(toTrain, axis=0)\n",
    "\n",
    "    train_x, train_y = split_xy(train)\n",
    "\n",
    "    val_x, val_y = split_xy(val)\n",
    "\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def evaluate(clf):\n",
    "    print(\"Cross validation\", sklearn.model_selection.cross_val_score(clf, X, y))\n",
    "    if hasattr(clf, \"decision_trees\"):\n",
    "        counter = Counter([t.tree_.feature[0] for t in clf.decision_trees])\n",
    "        first_splits = [(features[term[0]], term[1]) for term in counter.most_common()]\n",
    "        print(\"First splits\", first_splits)\n",
    "\n",
    "def getDataset(dataset):\n",
    "    if dataset == \"titanic\":\n",
    "        # Load titanic data\n",
    "        path_train = 'datasets/titanic/titanic_training.csv'\n",
    "        data = genfromtxt(path_train, delimiter=',', dtype=None)\n",
    "        path_test = 'datasets/titanic/titanic_testing_data.csv'\n",
    "        test_data = genfromtxt(path_test, delimiter=',', dtype=None)\n",
    "\n",
    "        data = np.delete(data, 6 ,axis=1) ##deleting ticket number\n",
    "        data[1:, 7] = data[1:, 7].astype('<U1').astype('|S18') ##changing cabin to first letter\n",
    "        np.put(data[:, 7], np.where(data[:, 7] == b''), stats.mode(data[data[:, 7]!=b''][:, 7]).mode[0]) \n",
    "\n",
    "        test_data = np.delete(test_data, 5 ,axis=1) ##deleting ticket number\n",
    "        test_data[1:, 6] = test_data[1:, 6].astype('<U1').astype('|S18') ##changing cabin to first letter\n",
    "        np.put(test_data[:, 6], np.where(test_data[:, 6] == b''), stats.mode(test_data[test_data[:, 6]!=b''][:, 6]).mode[0]) \n",
    "\n",
    "\n",
    "        y = data[1:, 0]  # label = survived\n",
    "        class_names = [\"Died\", \"Survived\"]\n",
    "\n",
    "        labeled_idx = np.where(y != b'')[0] ##finds indices where label is given\n",
    "        y = np.array(y[labeled_idx], dtype=np.int) #converts from byte strings into integers\n",
    "\n",
    "        # #print(\"\\n\\nPart (b): preprocessing the titanic dataset\")\n",
    "\n",
    "        X, onehot_features = preprocess(data[1:, 1:], onehot_cols=[1, 6, 7])\n",
    "        X = X[labeled_idx, :]\n",
    "\n",
    "        Z, _ = preprocess(test_data[1:, :], onehot_cols=[1, 6, 7])\n",
    "\n",
    "        features = list(data[0, 1:]) + onehot_features\n",
    "        # print(features, len(features))\n",
    "        # print(X.shape, Z.shape)\n",
    "        assert X.shape[1] == Z.shape[1]\n",
    "        \n",
    "\n",
    "    elif dataset == \"spam\":\n",
    "        features = [\n",
    "            \"pain\", \"private\", \"bank\", \"money\", \"drug\", \"spam\", \"prescription\", \"creative\",\n",
    "            \"height\", \"featured\", \"differ\", \"width\", \"other\", \"energy\", \"business\", \"message\",\n",
    "            \"volumes\", \"revision\", \"path\", \"meter\", \"memo\", \"planning\", \"pleased\", \"record\", \"out\",\n",
    "            \"semicolon\", \"dollar\", \"sharp\", \"exclamation\", \"parenthesis\", \"square_bracket\",\n",
    "            \"ampersand\"\n",
    "        ]\n",
    "        assert len(features) == 32\n",
    "\n",
    "        # Load spam data\n",
    "        path_train = 'datasets/spam_data/spam_data.mat'\n",
    "        data = scipy.io.loadmat(path_train)\n",
    "        X = data['training_data']\n",
    "        y = np.squeeze(data['training_labels'])\n",
    "        Z = data['test_data']\n",
    "        class_names = [\"Ham\", \"Spam\"]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Dataset %s not handled\" % dataset)\n",
    "\n",
    "    return X, y, Z, features, class_names\n",
    "\n",
    "def measure_accuracy(prediction, labels):\n",
    "    return np.sum(prediction == labels) / len(labels)\n",
    "\n",
    "def evaluateModel(X, y, split, model, filename=None, Z=None):\n",
    "    full = np.concatenate((X,y.reshape(-1,1)), axis=1)\n",
    "    np.random.shuffle(full)\n",
    "    train = full[:split, :]\n",
    "    val = full[split:, :]\n",
    "\n",
    "    train_x, train_y = split_xy(train)\n",
    "    train_y = train_y.reshape(-1,)\n",
    "\n",
    "    val_x, val_y = split_xy(val)\n",
    "    val_y = val_y.reshape(-1)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    prediction_train = model.predict(train_x)\n",
    "    prediction_val = model.predict(val_x)\n",
    "\n",
    "    if filename:\n",
    "        prediction_test = model.predict(Z)\n",
    "        results_to_csv(prediction_test, filename)\n",
    "        print(\"predictions saved\")\n",
    "\n",
    "    return measure_accuracy(prediction_train, train_y), measure_accuracy(prediction_val, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A code snippet to help you save your results into a kaggle accepted csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Usage results_to_csv(clf.predict(X_test))\n",
    "def results_to_csv(y_test, filename):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1  # Ensures that the index starts at 1. \n",
    "    df.to_csv(filename, index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may want to install \"gprof2dot\"\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydot\n",
    "\n",
    "eps = 1e-5  # a small number\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=3, feature_labels=None, m=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.features = feature_labels\n",
    "        self.left, self.right = None, None  # for non-leaf nodes\n",
    "        self.split_idx, self.thresh = None, None  # for non-leaf nodes\n",
    "        self.data, self.pred = None, None  # for leaf nodes\n",
    "\n",
    "        self.m = m\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_entropy(y):\n",
    "        base_probabilities = []\n",
    "        for class_label in np.unique(y):\n",
    "            count = len(y[np.where(y==class_label)])\n",
    "            base_probabilities.append(float(count / len(y)))\n",
    "\n",
    "        H_S = -1* sum([p_c * np.log2(p_c) for p_c in base_probabilities])\n",
    "        return H_S\n",
    "\n",
    "    @staticmethod\n",
    "    def information_gain(X, y, thresh):\n",
    "        #Base entropy calculations\n",
    "        H_S = DecisionTree.calculate_entropy(y)\n",
    "        \n",
    "\n",
    "        #Split entropy calculations\n",
    "        S_l_y = y[np.where(X < thresh)]\n",
    "        S_r_y = y[np.where(X >= thresh)]\n",
    "\n",
    "        H_Sl = DecisionTree.calculate_entropy(S_l_y)\n",
    "        H_Sr = DecisionTree.calculate_entropy(S_r_y)\n",
    "\n",
    "        H_after = ( len(S_l_y)*H_Sl + len(S_r_y)*H_Sr ) / len(y)\n",
    "\n",
    "        return H_S - H_after\n",
    "\n",
    "    def split(self, X, y, idx, thresh):\n",
    "        X0, idx0, X1, idx1 = self.split_test(X, idx=idx, thresh=thresh)\n",
    "        y0, y1 = y[idx0], y[idx1]\n",
    "        return X0, y0, X1, y1\n",
    "\n",
    "    def split_test(self, X, idx, thresh):\n",
    "        idx0 = np.where(X[:, idx] < thresh)[0]\n",
    "        idx1 = np.where(X[:, idx] >= thresh)[0]\n",
    "        X0, X1 = X[idx0, :], X[idx1, :]\n",
    "        return X0, idx0, X1, idx1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.max_depth > 0:\n",
    "            # compute entropy gain for all single-dimension splits,\n",
    "            # thresholding with a linear interpolation of 10 values\n",
    "            gains = []\n",
    "\n",
    "            original_data = X\n",
    "            if self.m:\n",
    "                attribute_bag = np.random.choice(list(range(len(self.features))), size=self.m, replace=False)\n",
    "                X = original_data[:, attribute_bag]\n",
    "            else:\n",
    "                attribute_bag = None\n",
    "                X = original_data\n",
    "\n",
    "            # The following logic prevents thresholding on exactly the minimum\n",
    "            # or maximum values, which may not lead to any meaningful node\n",
    "            # splits.\n",
    "\n",
    "            # print(\"original\", original_data.shape)\n",
    "            # print(\"attr_bag\", X.shape)\n",
    "\n",
    "            thresh = np.array([\n",
    "                np.linspace(np.min(X[:, i]) + eps, np.max(X[:, i]) - eps, num=10)\n",
    "                for i in range(X.shape[1])\n",
    "            ])\n",
    "            for i in range(X.shape[1]):\n",
    "                gains.append([self.information_gain(X[:, i], y, t) for t in thresh[i, :]])\n",
    "\n",
    "            gains = np.nan_to_num(np.array(gains))\n",
    "\n",
    "            #print(\"thresh\", thresh.shape)\n",
    "            #print(\"gainns\", gains.shape)\n",
    "\n",
    "            self.split_idx, thresh_idx = np.unravel_index(np.argmax(gains), gains.shape)\n",
    "           \n",
    "            #print(gains)\n",
    "            #print(\"split/thresh indx\", self.split_idx, thresh_idx)\n",
    "\n",
    "            self.thresh = thresh[self.split_idx, thresh_idx]\n",
    "\n",
    "            #print(\"thresh \", self.thresh)\n",
    "\n",
    "            if self.m:\n",
    "                self.split_idx = attribute_bag[self.split_idx]\n",
    "                #print(\"new index\", self.split_idx)\n",
    "\n",
    "            X0, y0, X1, y1 = self.split(original_data, y, idx=self.split_idx, thresh=self.thresh)\n",
    "            if X0.size > 0 and X1.size > 0:\n",
    "                self.left = DecisionTree(\n",
    "                    max_depth=self.max_depth - 1, feature_labels=self.features, m=self.m)\n",
    "                self.left.fit(X0, y0)\n",
    "                self.right = DecisionTree(\n",
    "                    max_depth=self.max_depth - 1, feature_labels=self.features, m=self.m)\n",
    "                self.right.fit(X1, y1)\n",
    "            else:\n",
    "                self.max_depth = 0\n",
    "                self.data, self.labels = original_data, y\n",
    "                self.pred = stats.mode(y).mode[0]\n",
    "        else:\n",
    "            self.data, self.labels = X, y\n",
    "            self.pred = stats.mode(y).mode[0]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, verbose=False):\n",
    "        if self.max_depth == 0:\n",
    "            return self.pred * np.ones(X.shape[0])\n",
    "        else:\n",
    "            if (verbose and X.shape[0] != 0):\n",
    "                print(\"feature\", self.features[self.split_idx], \"value\", X[0, self.split_idx], \">/<\", self.thresh)\n",
    "            \n",
    "            X0, idx0, X1, idx1 = self.split_test(X, idx=self.split_idx, thresh=self.thresh)\n",
    "            yhat = np.zeros(X.shape[0])\n",
    "            yhat[idx0] = self.left.predict(X0, verbose=verbose)\n",
    "            yhat[idx1] = self.right.predict(X1, verbose=verbose)\n",
    "            return yhat\n",
    "\n",
    "    \n",
    "class BaggedTrees:\n",
    "    def __init__(self, maxdepth=3, n=25, features=None, sample_size=None):\n",
    "        self.n = n\n",
    "        self.sample_size = sample_size\n",
    "        self.decision_trees = [\n",
    "            DecisionTree(max_depth=maxdepth, feature_labels=features)\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        assert self.sample_size <= len(y), \"Sample size cannot be greater or equal to input size\"\n",
    "\n",
    "        full = np.concatenate((X,y.reshape(-1,1)), axis=1)\n",
    "\n",
    "        for tree in self.decision_trees:\n",
    "            bagged_samples = np.random.choice(list(range(len(full))), size=self.sample_size, replace=True)\n",
    "\n",
    "            train_data = full[bagged_samples, :]\n",
    "            train_data_x = train_data[:, :-1]\n",
    "            train_data_y = train_data[:, -1:]\n",
    "\n",
    "            tree.fit(train_data_x, train_data_y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for tree in self.decision_trees:\n",
    "            predictions.append(tree.predict(X))\n",
    "\n",
    "        total_pred = np.vstack(predictions)\n",
    "        mode_prediction = stats.mode(total_pred).mode[0]\n",
    "\n",
    "        return mode_prediction\n",
    "\n",
    "class RandomForest(BaggedTrees):\n",
    "    def __init__(self, maxdepth=7, n=25, features=None, sample_size=None, m=1):\n",
    "        self.n = n\n",
    "        self.sample_size = sample_size\n",
    "        self.decision_trees = [\n",
    "            DecisionTree(max_depth=maxdepth, feature_labels=features, m=m)\n",
    "            for i in range(self.n)\n",
    "        ]\n",
    "\n",
    "    def crossValRF(X, y, features, m, sample_size=500):\n",
    "        for num_trees in [25, 40, 55, 70, 85, 100]:\n",
    "        #for depth in [3,4,5,6,7,8,9,10]:\n",
    "            kfold = generateKFold(X,y.reshape(-1, 1))\n",
    "\n",
    "            #print(\"using depth size {}\".format(depth))\n",
    "            print(\"Using Num Tree Size {}\".format(num_trees))\n",
    "            accuracies = []\n",
    "\n",
    "            for i in range(len(kfold)):\n",
    "                train_x, train_y, val_x, val_y = pickKFold(kfold, i)\n",
    "\n",
    "                dt = RandomForest(maxdepth=5, n=num_trees, features=features, m=m, sample_size=sample_size)\n",
    "                dt.fit(train_x, train_y)\n",
    "\n",
    "                val_predict = dt.predict(val_x)\n",
    "                val_y = val_y.reshape(-1,)\n",
    "\n",
    "                accuracies.append(np.sum(val_predict == val_y) / len(val_y))\n",
    "                print(\"KFold {} Val acc: \".format(i), accuracies[-1])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            print(\"Average validation accuracy: \", np.mean(accuracies))\n",
    "\n",
    "            print() \n",
    "\n",
    "    def crossValBaseDT(X, y, features):\n",
    "        for depth in [3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "            kfold = generateKFold(X,y.reshape(-1, 1))\n",
    "\n",
    "            print(\"Using Depth {}\".format(depth))\n",
    "            accuracies = []\n",
    "\n",
    "            for i in range(len(kfold)):\n",
    "                train_x, train_y, val_x, val_y = pickKFold(kfold, i)\n",
    "                dt = DecisionTree(max_depth=depth, feature_labels=features)\n",
    "                dt.fit(train_x, train_y)\n",
    "\n",
    "                val_predict = dt.predict(val_x)\n",
    "                val_y = val_y.reshape(-1,)\n",
    "\n",
    "                accuracies.append(np.sum(val_predict == val_y) / len(val_y))\n",
    "                print(\"KFold {} Val acc: \".format(i), accuracies[-1])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            print(\"Average validation accuracy: \", np.mean(accuracies))\n",
    "\n",
    "            print()   \n",
    "\n",
    "    def crossValBaggedDT(X, y, features, sample_size=500):\n",
    "        #for num_trees in [25, 40, 55, 70, 85, 100]:\n",
    "        for depth in [3,4,5,6,7,8,9,10]:\n",
    "            kfold = generateKFold(X,y.reshape(-1, 1))\n",
    "\n",
    "            print(\"using depth size {}\".format(depth))\n",
    "            #print(\"Using Num Tree Size {}\".format(num_trees))\n",
    "            accuracies = []\n",
    "\n",
    "            for i in range(len(kfold)):\n",
    "                train_x, train_y, val_x, val_y = pickKFold(kfold, i)\n",
    "\n",
    "                dt = BaggedTrees(maxdepth=depth, n=25, features=features, sample_size=sample_size)\n",
    "                dt.fit(train_x, train_y)\n",
    "\n",
    "                val_predict = dt.predict(val_x)\n",
    "                val_y = val_y.reshape(-1,)\n",
    "\n",
    "                accuracies.append(np.sum(val_predict == val_y) / len(val_y))\n",
    "                print(\"KFold {} Val acc: \".format(i), accuracies[-1])\n",
    "\n",
    "            accuracies = np.array(accuracies)\n",
    "            print(\"Average validation accuracy: \", np.mean(accuracies))\n",
    "\n",
    "            print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1 -- Base DT Train: 0.7631133671742809; Val: 0.7632850241545893\n",
      "Depth 5 -- Base DT Train: 0.8071065989847716; Val: 0.8009661835748793\n",
      "Depth 10 -- Base DT Train: 0.8358714043993232; Val: 0.8270531400966183\n",
      "Depth 15 -- Base DT Train: 0.8629441624365483; Val: 0.8057971014492754\n",
      "Depth 20 -- Base DT Train: 0.8726130045927; Val: 0.8270531400966183\n",
      "Depth 25 -- Base DT Train: 0.8791394730481025; Val: 0.821256038647343\n",
      "Depth 30 -- Base DT Train: 0.8846990572878898; Val: 0.8048309178743961\n",
      "Depth 35 -- Base DT Train: 0.8863911046652163; Val: 0.8318840579710145\n",
      "Depth 40 -- Base DT Train: 0.8854242204496011; Val: 0.8338164251207729\n",
      "Depth 45 -- Base DT Train: 0.8861493836113126; Val: 0.8328502415458937\n",
      "Depth 50 -- Base DT Train: 0.8897751994198695; Val: 0.8338164251207729\n",
      "Depth 55 -- Base DT Train: 0.8878414309886391; Val: 0.8241545893719807\n",
      "Depth 60 -- Base DT Train: 0.8885665941503504; Val: 0.8328502415458937\n",
      "Depth 65 -- Base DT Train: 0.884457336233986; Val: 0.8405797101449275\n",
      "Depth 70 -- Base DT Train: 0.8883248730964467; Val: 0.8280193236714976\n",
      "Depth 75 -- Base DT Train: 0.8883248730964467; Val: 0.8135265700483092\n",
      "Depth 80 -- Base DT Train: 0.8895334783659656; Val: 0.81256038647343\n",
      "Depth 85 -- Base DT Train: 0.8842156151800822; Val: 0.8405797101449275\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM Base DT Train: 0.8387720570461688; Val: 0.8164251207729468\n",
      "feature exclamation value 1.0 >/< 1e-05\n",
      "feature meter value 0.0 >/< 1e-05\n",
      "feature ampersand value 0.0 >/< 1e-05\n",
      "feature money value 0.0 >/< 1e-05\n",
      "feature volumes value 0.0 >/< 1e-05\n",
      "feature spam value 0.0 >/< 1e-05\n",
      "feature message value 0.0 >/< 1e-05\n",
      "feature prescription value 0.0 >/< 1e-05\n",
      "feature dollar value 0.0 >/< 1e-05\n",
      "feature pain value 0.0 >/< 1e-05\n",
      "feature exclamation value 0.0 >/< 1e-05\n",
      "feature meter value 3.0 >/< 1e-05\n",
      "SPAM Bagged DT Train: 0.8399806623156877; Val: 0.8222222222222222\n",
      "predictions saved\n",
      "Random Forest Train: 0.8339376359680928; Val: 0.8241545893719807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Spam DATASET\n",
    "    np.random.seed(267)\n",
    "\n",
    "    dataset = \"spam\"\n",
    "\n",
    "    X, y, Z, features, class_names = getDataset(dataset)\n",
    "\n",
    "    \"\"\"\n",
    "        Visualizing accuracies vs. depth. \n",
    "    \"\"\"\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    depths = [1,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85]\n",
    "\n",
    "    for depth in depths:\n",
    "        base_dt = DecisionTree(max_depth=depth, feature_labels=features)\n",
    "        base_train_acc, base_val_acc = evaluateModel(X, y, 4137, base_dt) #, filename=\"spam_base.csv\", Z=Z)\n",
    "        train_accuracies.append(base_train_acc)\n",
    "        valid_accuracies.append(base_val_acc)\n",
    "\n",
    "        print(\"Depth {} -- Base DT Train: {}; Val: {}\".format(depth, base_train_acc, base_val_acc))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(7, 7)) \n",
    "    axes.plot(depths, train_accuracies, '.r-') \n",
    "    axes.plot(depths, valid_accuracies, '.b-') \n",
    "    axes.legend(['Training', 'Validation'], loc='upper right') \n",
    "    axes.set_title(\"SPAM: Accuracies vs. Depth of Decision Tree\") \n",
    "    axes.set_xlabel(\"Depth of Tree\")\n",
    "    axes.set_ylabel(\"Accuracy\")\n",
    "    plt.ylim([0.7, .9])\n",
    "    plt.show()\n",
    "    plt.savefig(\"picture\")\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Training Decision Tree\n",
    "    \"\"\"\n",
    "\n",
    "    base_dt = DecisionTree(max_depth=10, feature_labels=features)\n",
    "    base_train_acc, base_val_acc = evaluateModel(X, y, 4137, base_dt)\n",
    "    print(\"SPAM Base DT Train: {}; Val: {}\".format(base_train_acc, base_val_acc))\n",
    "    \n",
    "    spam_sample = X[y==1, :][0,:].reshape(1, 32)\n",
    "    ham_sample = X[y==0, :][4, :].reshape(1, 32)\n",
    "\n",
    "    \"\"\"\n",
    "        Predictions for spam sample\n",
    "    \"\"\"\n",
    "\n",
    "    base_dt.predict(spam_sample, verbose=True)\n",
    " \n",
    "\n",
    "    \"\"\"\n",
    "        Predictions for ham sample\n",
    "    \"\"\"\n",
    "\n",
    "    base_dt.predict(ham_sample, verbose=True)\n",
    "\n",
    "    \"\"\"\n",
    "        Training Bagged Decision Tree\n",
    "    \"\"\"\n",
    "\n",
    "    #crossValBaggedDT(X, y, features, sample_size=3000)\n",
    "    bagged_dt = BaggedTrees(maxdepth=10, n=50, features=features, sample_size=3000)\n",
    "    bagged_train_acc, bagged_val_acc = evaluateModel(X, y, 4137, bagged_dt)\n",
    "    print(\"SPAM Bagged DT Train: {}; Val: {}\".format(bagged_train_acc, bagged_val_acc))\n",
    "\n",
    "    randforest = RandomForest(maxdepth=10, n=50, features=features, sample_size=3000, m=6)\n",
    "    rand_train_acc, rand_val_acc = evaluateModel(X, y, 4137, randforest, filename=\"spam_rf.csv\", Z=Z)\n",
    "    print(\"Random Forest Train: {}; Val: {}\".format(rand_train_acc, rand_val_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Kaggle and Writeup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [b'pclass', b'sex', b'age', b'sibsp', b'parch', b'fare', b'cabin', b'embarked', b'male', b'female', b'C', b'B', b'D', b'E', b'A', b'F', b'S', b'C', b'Q']\n",
      "Train/test size: (999, 19) (310, 19)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-da1b87ef1986>:95: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = genfromtxt(path_train, delimiter=',', dtype=None)\n",
      "<ipython-input-4-da1b87ef1986>:97: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  test_data = genfromtxt(path_test, delimiter=',', dtype=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base DT Train: 0.8457142857142858; Val: 0.8093645484949833\n",
      "predictions saved\n",
      "Bagged DT Train: 0.8657142857142858; Val: 0.7859531772575251\n",
      "Random Forest Train: 0.8228571428571428; Val: 0.7993311036789298\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pydot\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    ##TITANIC DATASET\n",
    "    np.random.seed(266)\n",
    "\n",
    "    dataset = \"titanic\"\n",
    "\n",
    "    X, y, Z, features, class_names = getDataset(dataset)\n",
    "\n",
    "    print(\"Features:\", features)\n",
    "    print(\"Train/test size:\", X.shape, Z.shape)\n",
    "    print()\n",
    "\n",
    "    \"\"\"\n",
    "        Training Base Decision Tree\n",
    "    \"\"\"\n",
    "\n",
    "    #crossValBaseDT(X, y, features)\n",
    "    # #Depth 6 indicated best Base Decision Tree Classifier (Titanic)\n",
    "    base_dt = DecisionTree(max_depth=6, feature_labels=features)\n",
    "    base_train_acc, base_val_acc = evaluateModel(X, y, 700, base_dt)\n",
    "    print(\"Base DT Train: {}; Val: {}\".format(base_train_acc, base_val_acc))\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Training shallow decision tree for writeup\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"max_depth\": 5,\n",
    "        # \"random_state\": 6,\n",
    "        \"min_samples_leaf\": 10,\n",
    "    }\n",
    "    base_dt = DecisionTree(max_depth=3, feature_labels=features)\n",
    "    base_train_acc, base_val_acc = evaluateModel(X, y, 700, base_dt)\n",
    "  #  clf = DecisionTreeClassifier(random_state=0, **params)\n",
    "  #  base_dt.fit(X, y)\n",
    "  #    evaluate(clf)\n",
    "    \n",
    "  #  # For OSX, may need the following for dot: brew install gprof2dot\n",
    "    \n",
    "  #  from pydot import graph_from_dot_data\n",
    "  #  import io\n",
    "\n",
    "  #  out = io.StringIO()\n",
    "  #  export_graphviz(clf, out_file=out, feature_names=features, class_names=class_names)\n",
    "  #  # For OSX, may need the following for dot: brew install gprof2dot\n",
    "  #  graph = graph_from_dot_data(out.getvalue())\n",
    "  #  graph_from_dot_data(out.getvalue())[0].write_pdf(\"%s-tree.pdf\" % dataset)\n",
    "    \n",
    "    # error in the package\n",
    "\n",
    "    \"\"\"\n",
    "        Training Bagged Decision Tree\n",
    "    \"\"\"\n",
    "\n",
    "    # crossValBaggedDT(X, y, features)\n",
    "    # #Depth 7 indicated best Bagged DT Classifier (Titanic)\n",
    "    # number trees, 40\n",
    "    bagged_dt = BaggedTrees(maxdepth=7, n=40, features=features, sample_size=700)\n",
    "    bagged_train_acc, bagged_val_acc = evaluateModel(X, y, 700, bagged_dt, filename=\"titanic_bdt.csv\", Z=Z)\n",
    "    print(\"Bagged DT Train: {}; Val: {}\".format(bagged_train_acc, bagged_val_acc))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        Training Random Forest\n",
    "    \"\"\"\n",
    "\n",
    "    #crossValRF(X, y, features, 4)\n",
    "    # #Depth 6, N=80 trees works best\n",
    "    randforest = RandomForest(maxdepth=6, n=80, features=features, sample_size=700, m=4)\n",
    "    rand_train_acc, rand_val_acc = evaluateModel(X, y, 700, randforest)\n",
    "    print(\"Random Forest Train: {}; Val: {}\".format(rand_train_acc, rand_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
